# Bank Transcript Scanner

## ğŸ“Œ Objective
This project aims to automate the extraction of key financial data from scanned bank transcripts (PDFs or images) for business auditing. The pipeline consists of:
1. **OCR Processing** â€“ Convert scanned bank transcripts into readable text.
2. **Bank Classification** â€“ Identify the bank to apply specific extraction rules.
3. **Data Extraction** â€“ Extract date, transaction ID, and amount from the transcript.
4. **Validation & Storage** â€“ Ensure extracted data accuracy and store it in a structured format.
5. **Web Deployment** â€“ Deploy the system as a web application for user-friendly access.

## ğŸ—ï¸ Project Structure
```
ğŸ“‚ bank_transcript_scanner
â”‚â”€â”€ ğŸ“ data                  # Raw and processed data
â”‚   â”œâ”€â”€ ğŸ“‚ raw               # Original scanned PDFs/images of bank statements
â”‚   â”œâ”€â”€ ğŸ“‚ processed         # Extracted text from OCR
â”‚â”€â”€ ğŸ“ models                # Trained models for classification & extraction
â”‚   â”œâ”€â”€ bank_classifier.pkl  # Bank classification model
â”‚â”€â”€ ğŸ“ notebooks             # Jupyter Notebooks for exploration and testing
â”‚â”€â”€ ğŸ“ src                   # Source code
â”‚   â”œâ”€â”€ ğŸ“‚ ocr               # OCR processing scripts
â”‚   â”‚   â”œâ”€â”€ preprocess.py    # Preprocess images (grayscale, thresholding, etc.)
â”‚   â”‚   â”œâ”€â”€ ocr_engine.py    # Extract text using Tesseract OCR
â”‚   â”‚   â”œâ”€â”€ text_cleaning.py # Clean and format extracted text
â”‚   â”œâ”€â”€ ğŸ“‚ classification    # Bank classification model
â”‚   â”‚   â”œâ”€â”€ train_classifier.py # Train ML model for bank classification
â”‚   â”‚   â”œâ”€â”€ classify_bank.py    # Classify bank from extracted text
â”‚   â”‚   â”œâ”€â”€ bank_classifier.pkl # Saved ML model
â”‚   â”œâ”€â”€ ğŸ“‚ extraction        # Extract key details from statements
â”‚   â”‚   â”œâ”€â”€ extract_data.py  # Extract dates, amounts, transaction IDs
â”‚   â”‚   â”œâ”€â”€ validation.py    # Validate extracted information
â”‚   â”œâ”€â”€ ğŸ“‚ backend           # Backend API (FastAPI)
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ routes.py        # API routes for OCR, classification, extraction
â”‚   â”‚   â”œâ”€â”€ models.py        # Define database models
â”‚   â”‚   â”œâ”€â”€ database.py      # Database connection setup
â”‚   â”‚   â”œâ”€â”€ requirements.txt # Backend dependencies
â”‚   â”œâ”€â”€ ğŸ“‚ frontend          # Frontend (Next.js)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ components    # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ pages         # Main pages (upload, results, etc.)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ public        # Static assets (icons, logos)
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ styles        # CSS/Styling files
â”‚   â”‚   â”œâ”€â”€ package.json     # Frontend dependencies
â”‚   â”‚   â”œâ”€â”€ next.config.js   # Next.js configuration
â”‚   â”‚   â”œâ”€â”€ App.js           # Main app file
â”‚   â”‚   â”œâ”€â”€ index.js         # Home page
â”‚   â”œâ”€â”€ main.py              # Entry point for running pipeline (CLI)
â”‚â”€â”€ ğŸ“ tests                 # Unit tests for OCR, classification, extraction
â”‚   â”œâ”€â”€ test_ocr.py          # Test OCR extraction
â”‚   â”œâ”€â”€ test_classification.py # Test bank classification model
â”‚   â”œâ”€â”€ test_extraction.py   # Test data extraction
â”‚â”€â”€ ğŸ“ deployment            # Deployment configurations (Docker, cloud, etc.)
â”‚   â”œâ”€â”€ Dockerfile           # Docker setup
â”‚   â”œâ”€â”€ docker-compose.yml   # Multi-container setup (DB, API, frontend)
â”‚   â”œâ”€â”€ config.yaml          # Configuration settings
â”‚â”€â”€ requirements.txt         # Backend dependencies
â”‚â”€â”€ README.md                # Project documentation
â”‚â”€â”€ LICENSE                  # License information

```

## ğŸ› ï¸ Setup Instructions
1. Clone the repository:
   ```bash
   git clone https://github.com/chantharith-NY/Bank-Transcript-Scanner.git
   cd bank_transcript_scanner
   ```
2. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Run the pipeline (example):
   ```bash
   python src/main.py --input data/raw/sample.pdf
   ```

## ğŸŒ Web Deployment
- **Frontend**: Built with React or Next.js for a modern and responsive UI.
- **Backend**: Flask or FastAPI for API endpoints handling OCR, classification, and extraction.
- **Deployment**: Dockerized setup with AWS, Vercel, or Heroku hosting.
- **User Interaction**: Upload transcripts, view extracted data, download results, and manage scanned records.

## ğŸ” Features
- **OCR Processing**: Uses Tesseract OCR.
- **Bank Classification**: ML model to categorize bank transcripts.
- **Data Extraction**: NLP and regex-based extraction of key financial details.
- **Web Interface**: Allows easy document uploads and review of extracted data.
- **Scalability**: Supports multiple bank formats and integrations.

## ğŸš€ Next Steps
- Implement OCR pipeline.
- Train classification model.
- Develop robust data extraction logic.
- Build and deploy the full-stack web application.

## ğŸ“œ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---
ğŸ‘¨â€ğŸ’» Developed by: 
- LENG Devid
- LY Chungheang
- NANG Chettra
- NGOUN Lyhorng
- NHEN Theary
- NY Chantharith