# Bank Transcript Scanner

## ğŸ“Œ Objective
This project aims to automate the extraction of key financial data from scanned bank transcripts (PDFs or images) for business auditing. The pipeline consists of:
1. **OCR Processing** â€“ Convert scanned bank transcripts into readable text.
2. **Bank Classification** â€“ Identify the bank to apply specific extraction rules.
3. **Data Extraction** â€“ Extract date, transaction ID, and amount from the transcript.
4. **Validation & Storage** â€“ Ensure extracted data accuracy and store it in a structured format.
5. **Web Deployment** â€“ Deploy the system as a web application for user-friendly access.

## ğŸ—ï¸ Project Structure
```
ğŸ“‚ bank_transcript_scanner
â”‚â”€â”€ ğŸ“ data                  # Raw and processed data
â”‚   â”œâ”€â”€ ğŸ“‚ raw                # Original scanned PDFs or images
â”‚   â”œâ”€â”€ ğŸ“‚ processed          # Text extracted from OCR
â”‚â”€â”€ ğŸ“ models                # Trained models for classification & extraction
â”‚â”€â”€ ğŸ“ notebooks             # Jupyter Notebooks for exploration and testing
â”‚â”€â”€ ğŸ“ src                   # Source code
â”‚   â”œâ”€â”€ ğŸ“‚ ocr               # OCR processing scripts
â”‚   â”œâ”€â”€ ğŸ“‚ classification    # Bank classification model
â”‚   â”œâ”€â”€ ğŸ“‚ extraction        # Data extraction logic
â”‚   â”œâ”€â”€ ğŸ“‚ backend           # Backend API (FastAPI)
â”‚   â”œâ”€â”€ ğŸ“‚ frontend          # Frontend (Next.js)
â”‚   â”œâ”€â”€ main.py              # Entry point of the pipeline
â”‚â”€â”€ ğŸ“ tests                 # Unit tests for OCR, classification, extraction
â”‚â”€â”€ ğŸ“ deployment            # Deployment configurations (Docker, cloud, etc.)
â”‚â”€â”€ requirements.txt         # Dependencies
â”‚â”€â”€ README.md                # Project documentation
â”‚â”€â”€ LICENSE                  # License information
```

## ğŸ› ï¸ Setup Instructions
1. Clone the repository:
   ```bash
   git clone https://github.com/chantharith-NY/Bank-Transcript-Scanner.git
   cd bank_transcript_scanner
   ```
2. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Run the pipeline (example):
   ```bash
   python src/main.py --input data/raw/sample.pdf
   ```

## ğŸŒ Web Deployment
- **Frontend**: Built with React or Next.js for a modern and responsive UI.
- **Backend**: Flask or FastAPI for API endpoints handling OCR, classification, and extraction.
- **Deployment**: Dockerized setup with AWS, Vercel, or Heroku hosting.
- **User Interaction**: Upload transcripts, view extracted data, download results, and manage scanned records.

## ğŸ” Features
- **OCR Processing**: Uses Tesseract OCR.
- **Bank Classification**: ML model to categorize bank transcripts.
- **Data Extraction**: NLP and regex-based extraction of key financial details.
- **Web Interface**: Allows easy document uploads and review of extracted data.
- **Scalability**: Supports multiple bank formats and integrations.

## ğŸš€ Next Steps
- Implement OCR pipeline.
- Train classification model.
- Develop robust data extraction logic.
- Build and deploy the full-stack web application.

## ğŸ“œ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---
ğŸ‘¨â€ğŸ’» Developed by: 
- LENG Devid
- LY Chungheang
- NANG Chettra
- NGOUN Lyhorng
- NHEN Theary
- NY Chantharith